@version: 4.8
@include "scl.conf"		# Cisco、PaloAlto、Fortigate などのログのパースも含まれる
# 書き換えたら make conf_check で構文チェックを実行する

# RFC 5424  :  514/udp  514/tcp
# Cisco用   : 3514/udp 3514/tcp
# RFC 3164  : 4514/udp 4514/tcp
# fortigate : 5514/udp 5514/tcp
# fluent_bit から json 構造化ログ
#           : 6514/tcp
# AlaxalA用 : 7514/udp 7514/tcp
# CEF用     :  999/tcp (internal 9999)

options {
  chain-hostnames(off); # ホスト名だけで送られてきたときドメイン名を補完しない
  use-dns(no); use-fqdn(no); dns-cache(no); keep-hostname(yes);
  create-dirs(yes); dir-perm(0755); perm(0644);

  frac-digits(6);	# 秒以下の桁数を指定
  ts-format(rfc3339);   # ファイルへ書きだすときの形式を指定 (RFC 3339形式) (マイクロ秒まで)
                        #  ts-format(iso); だと秒単位まで
  stats(freq(86400));
  threaded(yes);
};

#==================================
# 1. ソース (受信)
#==================================
# UDP/TCP 一般用 RFC 5424 用 改行区切り (514/udp,514/tcp)
source s_rfc5424 {
  network(ip(0.0.0.0) port(514) transport("udp") flags(syslog-protocol) log-msg-size(65536));
  network(ip(0.0.0.0) port(514) transport("tcp") flags(syslog-protocol) log-msg-size(65536));
};

# RFC 5424 octet-counted 用 (2514/tcp)
source s_rfc5424_octet {
  syslog(
    ip(0.0.0.0) port(2514) transport("tcp") flags(syslog-protocol) log-msg-size(65536) max-connections(100)
  );
};

# Cisco 機器用 (3514/udp, 3514/tcp)
source s_cisco {
  # Cisco は独自形式で送信してくるため、flags(no-parse, store-raw-message) を使用
  # cisco-parser() が全体をパースする
  network(ip(0.0.0.0) port(3514) transport("udp") flags(no-parse, store-raw-message) log-msg-size(65536));
  network(ip(0.0.0.0) port(3514) transport("tcp") flags(no-parse, store-raw-message) log-msg-size(65536));
};

# RFC 3164 (IXルーター等) 受信用 (4514/udp)
# flags(syslog-protocol) を*指定しない*
source s_rfc3164 {
  network(ip(0.0.0.0) port(4514) transport("udp") log-msg-size(65536));
  network(ip(0.0.0.0) port(4514) transport("tcp") log-msg-size(65536));
};

# TCP/UDP Fortigate 用 (5514/udp)
source s_fortigate {
  network(ip(0.0.0.0) port(5514) transport("udp") flags(no-parse, store-raw-message) log-msg-size(65536));
  network(ip(0.0.0.0) port(5514) transport("tcp") flags(no-parse, store-raw-message) log-msg-size(65536));
};

# Palo Alto (PAN-OS) 用 (5515/udp, 5515/tcp)
source s_panos {
  network(
    port(5515)
    transport("tcp")
    flags(no-parse, store-raw-message)
  );
  network(
    port(5515)
    transport("udp")
    flags(no-parse, store-raw-message)
    # UDP does not support multi-line-mode in the same way, but usually UDP packets are one log per packet.
    # If fragmentation happens, it's handled at IP layer.
  );
};

# JSON 構造化ログ受信用 Fluent-bit 等の出力を受ける (6514/tcp)
source s_fluent_bit {
  # Fluent-bit は RFC 5424 準拠なので syslog() のままでも可
  # network() に変更しても動作します
  network(ip(0.0.0.0) port(6514) flags(syslog-protocol) log-msg-size(65536));
};

# AlaxalA スイッチ用 (7514/udp, 7514/tcp)
source s_alaxala {
  network(ip(0.0.0.0) port(7514) transport("udp") log-msg-size(65536));
  network(ip(0.0.0.0) port(7514) transport("tcp") log-msg-size(65536));
};

# CEF ログ受信用 (999/tcp)
source s_cef {
  network(ip(0.0.0.0) port(999) transport("tcp") flags(no-parse) log-msg-size(65536) max-connections(200));
};

#==================================
# 2. フィルタ (分類担当)
#==================================
# FortiGateのIPアドレスでフィルタリング
filter f_fortigate {
  host("192.168.0.254") or netmask("127.0.0.0/30");
};

# CentreCOMスイッチのIPアドレスでフィルタリング
filter f_centrecom {
  host("172.31.220.99");
  # 複数のCentreCOMスイッチがある場合は以下のように追加
  # host("172.31.220.99") or host("172.31.220.100") or netmask("172.31.220.0/24");
};

# YAMAHA RTX 用 (旧)
filter f_old_yamaha {
  host(^192.168.99.99$) or
  host(^192.168.99.222$)
};

# Palo Alto 用フィルタ (SYSTEM, TRAFFIC, THREAT, CONFIG)
filter f_paloalto {
  message(",SYSTEM,") or message(",TRAFFIC,") or message(",THREAT,") or message(",CONFIG,");
};

#==================================
# 3. パーサー (項目の分解)
#==================================
# Cisco 用パーサー (構造化データ + メッセージパース)
parser p_cisco {
  channel {
    # 1. 構造化データ部分を抽出（あればマッチ、なければスキップ）
    parser {
      regexp-parser(
        patterns(
          # パターン1: 構造化データあり (柔軟対応 - 任意のパラメータを許容) + seqあり
          '^\<(?<pri>[0-9]+)\>(?<seq1>[0-9]+): (?:(?<cisco_hostname>[^ ]+): )?\[syslog@9[^\]]+\]: (?<seq>[0-9]+): (?<remaining_msg>.*)',
          # パターン2: 構造化データあり (柔軟対応) + seqなし
          '^\<(?<pri>[0-9]+)\>(?<seq1>[0-9]+): (?:(?<cisco_hostname>[^ ]+): )?\[syslog@9[^\]]+\]: (?<remaining_msg>.*)',
          # パターン3: 構造化データ壊れ (]: だけ残っている) + ホスト名あり
          '^\<(?<pri>[0-9]+)\>(?<seq1>[0-9]+): (?:(?<cisco_hostname>[^ ]+): )?\]: (?<remaining_msg>.*)',
          # パターン4: 構造化データなし + ホスト名あり + seqあり
          '^\<(?<pri>[0-9]+)\>(?<seq1>[0-9]+): (?:(?<cisco_hostname>[^ ]+): )?(?<seq>[0-9]+): (?<remaining_msg>.*)',
          # パターン5: 構造化データなし + ホスト名あり (シンプル)
          '^\<(?<pri>[0-9]+)\>(?<seq1>[0-9]+): (?:(?<cisco_hostname>[^ ]+): )?(?<remaining_msg>.*)',
          # パターン6: priority なし (通常のCisco IOS形式)
          '^(?<seq1>[0-9]+): (?<remaining_msg>.*)'
        )
      );
    };
    # 2. MESSAGEを再設定
    rewrite {
      set("${remaining_msg}", value("MESSAGE"));
    };
    # 3. タイムスタンプ抽出とパース（失敗しても継続）
    # まずタイムスタンプとタイムゾーンを抽出
    parser {
      regexp-parser(
        patterns(
          # パターン1: 年あり + タイムゾーン名付き + ミリ秒あり (例: Nov  9 2025 22:23:49.895 UTC:)
          '^(?<cisco_timestamp>[A-Z][a-z]+ +[0-9]+ +[0-9]{4} +[0-9]+:[0-9]+:[0-9]+\.[0-9]+) +(?<cisco_tz>[A-Z]{2,5}): (?<cisco_msg_after_ts>.*)',
          # パターン2: 年あり + タイムゾーンなし + ミリ秒あり (例: Nov  9 2025 22:23:49.895:)
          '^(?<cisco_timestamp>[A-Z][a-z]+ +[0-9]+ +[0-9]{4} +[0-9]+:[0-9]+:[0-9]+\.[0-9]+): (?<cisco_msg_after_ts>.*)',
          # パターン3: 年あり + タイムゾーン名付き + ミリ秒なし (例: Nov  9 2025 22:28:40 UTC:)
          '^(?<cisco_timestamp>[A-Z][a-z]+ +[0-9]+ +[0-9]{4} +[0-9]+:[0-9]+:[0-9]+) +(?<cisco_tz>[A-Z]{2,5}): (?<cisco_msg_after_ts>.*)',
          # パターン4: 年あり + タイムゾーンなし + ミリ秒なし (例: Nov  9 2025 22:28:40:)
          '^(?<cisco_timestamp>[A-Z][a-z]+ +[0-9]+ +[0-9]{4} +[0-9]+:[0-9]+:[0-9]+): (?<cisco_msg_after_ts>.*)',
          # パターン5: 年なし + タイムゾーン名付き + ミリ秒あり (例: Nov 10 07:17:05.557 JST:)
          '^(?<cisco_timestamp>[A-Z][a-z]+ +[0-9]+ +[0-9]+:[0-9]+:[0-9]+\.[0-9]+) +(?<cisco_tz>[A-Z]{2,5}): (?<cisco_msg_after_ts>.*)',
          # パターン6: 年なし + タイムゾーンなし + ミリ秒あり (例: Nov 10 07:17:05.557:)
          '^(?<cisco_timestamp>[A-Z][a-z]+ +[0-9]+ +[0-9]+:[0-9]+:[0-9]+\.[0-9]+): (?<cisco_msg_after_ts>.*)',
          # パターン7: 年なし + タイムゾーン名付き + ミリ秒なし (例: Nov  9 22:19:15 JST:)
          '^(?<cisco_timestamp>[A-Z][a-z]+ +[0-9]+ +[0-9]+:[0-9]+:[0-9]+) +(?<cisco_tz>[A-Z]{2,5}): (?<cisco_msg_after_ts>.*)',
          # パターン8: 年なし + タイムゾーンなし + ミリ秒なし (例: Nov  9 22:19:15:)
          '^(?<cisco_timestamp>[A-Z][a-z]+ +[0-9]+ +[0-9]+:[0-9]+:[0-9]+): (?<cisco_msg_after_ts>.*)'
        )
        template("${MESSAGE}")
      );
    };
    # タイムスタンプが抽出できた場合のみパース
    if ("${cisco_timestamp}" ne "") {
      # タイムゾーンに応じて解釈を変更
      if ("${cisco_tz}" eq "JST") {
        parser {
          date-parser(
            format(
              "%b %d %Y %H:%M:%S.%f",
              "%b %d %Y %H:%M:%S",
              "%b %d %H:%M:%S.%f",
              "%b %d %H:%M:%S"
            )
            template("${cisco_timestamp}")
            time-zone("Asia/Tokyo")
          );
        };
      } elif ("${cisco_tz}" eq "UTC") {
        parser {
          date-parser(
            format(
              "%b %d %Y %H:%M:%S.%f",
              "%b %d %Y %H:%M:%S",
              "%b %d %H:%M:%S.%f",
              "%b %d %H:%M:%S"
            )
            template("${cisco_timestamp}")
            time-zone("UTC")
          );
        };
      } else {
        # タイムゾーン指定なし or その他のタイムゾーンはUTCとして扱う
        parser {
          date-parser(
            format(
              "%b %d %Y %H:%M:%S.%f",
              "%b %d %Y %H:%M:%S",
              "%b %d %H:%M:%S.%f",
              "%b %d %H:%M:%S"
            )
            template("${cisco_timestamp}")
            time-zone("UTC")
          );
        };
      };
      # タイムスタンプ以降のメッセージに置き換え
      rewrite {
        set("${cisco_msg_after_ts}", value("MESSAGE"));
      };
    };
    # 4. Cisco メッセージをパース（失敗しても継続）
    junction {
      channel {
        parser {
          cisco-parser();
        };
      };
      channel { };
    };
    # 5. HOSTを設定
    # Ciscoホスト名があればそれを使用、なければIPアドレスを使用
    rewrite {
      # まずIPアドレスを設定
      set("${HOST_FROM}", value("HOST"));
      # cisco_hostnameが存在すれば上書き
      set("${cisco_hostname}", value("HOST") condition("${cisco_hostname}" ne ""));
    };
    # 7. 不要なフィールドを削除
    rewrite {
      unset(value("remaining_msg"));
      unset(value("cisco_timestamp"));
      unset(value("cisco_msg_after_ts"));
      unset(value("cisco_hostname"));
      unset(value("seq1"));  # seq2があるので不要
      unset(value("pri"));   # facility と priority があるので不要
      unset(value("0"));
      unset(value("1"));
      unset(value("2"));
      unset(value("3"));
    };
  };
};

# CentreCOM 用パーサー
parser p_centrecom {
  channel {
    # 1. CentreCOMフォーマットをパース
    # <pri>YYYY MMM DD HH:MM:SS hostname program[pid]: message
    parser {
      regexp-parser(
        patterns(
          # パターン1: program[pid]あり
          '^\<(?<pri>[0-9]+)\>(?<year>[0-9]{4}) +(?<month>[A-Z][a-z]+) +(?<day>[0-9]+) +(?<time>[0-9]+:[0-9]+:[0-9]+) +(?<centrecom_hostname>[^ ]+) +(?<program>[^\[: ]+)\[(?<pid>[0-9]+)\]: (?<msg>.*)',
          # パターン2: program のみ ([pid]なし)
          '^\<(?<pri>[0-9]+)\>(?<year>[0-9]{4}) +(?<month>[A-Z][a-z]+) +(?<day>[0-9]+) +(?<time>[0-9]+:[0-9]+:[0-9]+) +(?<centrecom_hostname>[^ ]+) +(?<program>[^:]+): (?<msg>.*)'
        )
      );
    };
    
    # 2. タイムスタンプをパース
    if ("${year}" ne "") {
      parser {
        date-parser(
          format("%Y %b %d %H:%M:%S")
          template("${year} ${month} ${day} ${time}")
          time-zone("Asia/Tokyo")
        );
      };
    };
    
    # 3. フィールドを設定
    rewrite {
      set("${msg}", value("MESSAGE"));
      set("${centrecom_hostname}", value("HOST"));
      set("${program}", value("PROGRAM"));
      set("${pid}", value(".SDATA.meta.pid") condition("${pid}" ne ""));
    };
    
    # 6. 不要なフィールドを削除
    rewrite {
      unset(value("year"));
      unset(value("month"));
      unset(value("day"));
      unset(value("time"));
      unset(value("centrecom_hostname"));
      unset(value("msg"));
      unset(value("pri"));
      unset(value("pid"));
    };
  };
};

# FortiGate 用パーサー
parser p_fortigate {fortigate-parser();};

# AlaxalA 用パーサー
parser p_alaxala {
  channel {
    parser {
      regexp-parser(
        patterns(
          '^(?<log_type>[A-Z]+) +(?<event_date>[0-9]+/[0-9]+) +(?<event_time>[0-9]+:[0-9]+:[0-9]+) +(?<alaxala_severity>[EWID][0-9]) +(?<module>[A-Z]+) +(?<detail>.*)',
          '^(?<log_type>[A-Z]+) +(?<alaxala_severity>[EWID][0-9]) +(?<module>[A-Z]+) +(?<detail>.*)'
        )
        template("${MESSAGE}")
      );
    };
    
    rewrite {
      set("${alaxala_severity} ${module}", value("PROGRAM") condition("${alaxala_severity}" ne "" and "${module}" ne ""));
      set("${detail}", value("MESSAGE") condition("${detail}" ne ""));
      set("${log_type}", value(".alaxala.log_type") condition("${log_type}" ne ""));
      set("${event_date}", value(".alaxala.event_date") condition("${event_date}" ne ""));
      set("${event_time}", value(".alaxala.event_time") condition("${event_time}" ne ""));
      set("${alaxala_severity}", value(".alaxala.severity") condition("${alaxala_severity}" ne ""));
      set("${module}", value(".alaxala.module") condition("${module}" ne ""));
      set("${PID}", value(".alaxala.function_number") condition("${PID}" ne ""));
    };
    
    rewrite {
      unset(value("log_type"));
      unset(value("event_date"));
      unset(value("event_time"));
      unset(value("alaxala_severity"));
      unset(value("module"));
      unset(value("detail"));
      unset(value("0"));
      unset(value("1"));
      unset(value("2"));
      unset(value("3"));
      unset(value("4"));
      unset(value("5"));
      unset(value("6"));
    };
  };
};

# JSON 用パーサー
parser p_json {json-parser();};

# Palo Alto (PAN-OS) 用パーサー
parser p_panos {
  channel {
    parser {
      panos-parser(template("${MESSAGE}"));
    };
  };
};

# CEF 用パーサー
parser p_cef {
  channel {
    parser {
      regexp-parser(
        patterns('.*CEF:(?<cef_version>[^|]+)[|](?<device_vendor>[^|]*)[|](?<device_product>[^|]*)[|](?<device_version>[^|]*)[|](?<device_event_class_id>[^|]*)[|](?<name>[^|]*)[|](?<severity>[^|]*)[|](?<cef_extension>.*)')
        prefix("_cef.")
      );
    };
    # 2. 元のMESSAGEを退避 (JSON出力の message フィールド用)
    rewrite {
      set("${MESSAGE}", value("saved_message"));
    };
    # 3. MESSAGEを拡張フィールド部分に書き換え (以降のKVパース用)
    rewrite {
      set("${_cef.cef_extension}", value("MESSAGE"));
    };
    # 4. KVペアとしてパース
    parser {
      kv-parser(
        prefix("_cef.")
        template("${MESSAGE}")
      );
    };

    # 5. agentRt があればマイクロ秒に変換してタイムスタンプ用変数を設定
    rewrite {
      set("${_cef.agentRt}000", value(".us_timestamp") condition("${_cef.agentRt}" ne ""));
    };

    # 6. 不要なフィールドの削除
    rewrite {
      unset(value("_cef.cef_extension"));
      unset(value("0"));
      unset(value("1"));
      unset(value("2"));
      unset(value("_cef.0"));
      unset(value("_cef.1"));
      unset(value("_cef.2"));
      unset(value("_cef.3"));
      unset(value("_cef.4"));
      unset(value("_cef.5"));
      unset(value("_cef.6"));
      unset(value("_cef.7"));
      unset(value("_cef.8"));
    };
  };
};

# CEF タイムスタンプ変換用パーサー
parser p_cef_timestamp {
  channel {
    # eventtime (小文字) と eventTime (CamelCase) の両方をチェックして tmp_epoch にセット
    if ("${_cef.eventtime}" ne "") {
         rewrite { set("${_cef.eventtime}", value("tmp_epoch")); };
    };
    if ("${_cef.eventTime}" ne "") {
         rewrite { set("${_cef.eventTime}", value("tmp_epoch")); };
    };

    if ("${tmp_epoch}" ne "") {
        parser {
            # 13桁のミリ秒を 秒(10桁)とミリ秒(3桁)に分割
            regexp-parser(
                patterns('^(?<tmp_sec>[0-9]{10})(?<tmp_msec>[0-9]{3})')
                template("${tmp_epoch}")
            );
            # メッセージのタイムスタンプとしてパース (これで $ISODATE が更新される)
            date-parser(
                format("%s.%f")
                template("${tmp_sec}.${tmp_msec}")
            );
        };
        # 更新された $ISODATE を新しいフィールドにセット
        rewrite {
            set("${ISODATE}", value("_cef.eventtime_iso"));
            # 一時変数の削除
            unset(value("tmp_sec"));
            unset(value("tmp_msec"));
            unset(value("tmp_epoch"));
        };
    };
  };
};



#==================================
# 4. 宛先 (送信)
#==================================
# OpenObserve に送る
destination d_openobserve {
  openobserve-log(
    persist_name("openobserve")
    url("http://OpenObserve")
    port(5080)
    organization("default")
    stream("syslog-ng")
    user("root@root.root")
    password("root")
    time-zone("Asia/Tokyo")
    record("--scope rfc5424 --scope all-nv-pairs --exclude DATE --key ISODATE @timestamp=${ISODATE} host=${HOST}")
    disk-buffer(
      reliable(yes)
      mem-buf-size(1048576)
      disk-buf-size(104857600)
      dir("/buffer/to_OpenObserve/")
    )
    workers(4)
  );
};

# CEFログ用デスティネーション (OpenObserve)
destination d_openobserve_cef {
  openobserve-log(
    persist_name("openobserve_cef")
    url("http://OpenObserve")
    port(5080)
    organization("default")
    stream("syslog-ng")
    user("root@root.root")
    password("root")
    time-zone("Asia/Tokyo")

    # _cef.* をネストしてJSON化 + host_from, source, facility, priority, message, timestamp
    body("$(format-json --key _cef.* --rekey . --exclude DATE --key ISODATE @timestamp=${.final_timestamp} host=${HOST} host_from=${HOST_FROM} source=${SOURCE} facility=${FACILITY} priority=${PRIORITY} message=${saved_message})")

    disk-buffer(
      reliable(yes)
      mem-buf-size(1048576)
      disk-buf-size(104857600)
      dir("/buffer/to_OpenObserve_cef/")
    )
    workers(4)
  );
};

# デバッグ用: CEFログをローカルファイルにも出力 (テール確認用)
destination d_cef_debug {
  file("/buffer/cef_debug.log" template("--------------------------------------------------------------------------------\n[RAW INPUT]\n${saved_message}\n\n[JSON OUTPUT]\n$(format-json --key _cef.* --rekey . --exclude DATE --key ISODATE @timestamp=${.final_timestamp} host_from=${HOST_FROM} source=${SOURCE} facility=${FACILITY} priority=${PRIORITY} message=${saved_message})\n--------------------------------------------------------------------------------\n\n"));
};

# json 構造化済みのログ用
destination d_openobserve_json {
  openobserve-log(
    persist_name("openobserve_json")
    url("http://OpenObserve")
    port(5080)
    organization("default")
    stream("syslog-ng")
    user("root@root.root")
    password("root")
    time-zone("Asia/Tokyo")
    body("${MESSAGE}")
    disk-buffer(
      reliable(yes)
      mem-buf-size(1048576)
      disk-buf-size(104857600)
      dir("/buffer/to_OpenObserve/")
    )
    workers(4)
  );
};

#==================================
# 5. ログ処理のパイプライン定義
#==================================
# json 構造化ログ受信用
log {
  source(s_fluent_bit);
  parser(p_json);
  destination(d_openobserve_json);
  flags(final);
};

# YAMAHA RTX 用
log {
  source(s_rfc5424);
  filter(f_old_yamaha);
  rewrite {
    set("${PROGRAM} ${MESSAGE}", value("MESSAGE"));
    unset(value("PROGRAM"));
  };
  destination(d_openobserve);
  flags(final);
};

# Fortigate 用
log {
  source(s_fortigate);
  filter(f_fortigate);
  parser(p_fortigate);
  destination(d_openobserve);
  flags(final);
};

# AlaxalA スイッチ用パイプライン
log {
  source(s_alaxala);
  parser(p_alaxala);
  destination(d_openobserve);
  flags(final);
};

# CentreCOM 機器用パイプライン (IPアドレスでフィルタ)
log {
  source(s_rfc5424);
  filter(f_centrecom);
  parser(p_centrecom);
  destination(d_openobserve);
  flags(final);
};

# Palo Alto 機器用パイプライン
log {
  source(s_panos);
  parser(p_panos);
  destination(d_openobserve);
  flags(final);
};

# Cisco 機器用パイプライン
log {
  source(s_cisco);
  parser(p_cisco);
  destination(d_openobserve);
  flags(final);
};

# それ以外の全てのログの処理
log {
  source(s_rfc3164);
  source(s_rfc5424);
  source(s_rfc5424_octet);
  destination(d_openobserve);
  flags(final);
};

# CEF ログ用 Timestamp 最終決定
rewrite r_cef_final_timestamp {
  # デフォルトは ISODATE (受信時刻 or p_cef_timestampの結果)
  set("${ISODATE}", value(".final_timestamp"));
  # .us_timestamp (agentRt由来) があれば優先
  set("${.us_timestamp}", value(".final_timestamp") condition("${.us_timestamp}" ne ""));
};

# CEF ログ用パイプライン
log {
  source(s_cef);
  parser(p_cef);
  parser(p_cef_timestamp);
  rewrite(r_cef_final_timestamp);
  destination(d_openobserve_cef);
  destination(d_cef_debug);
  flags(final);
};

#==================================
# 6. syslog-ng 自身の動作ログは docker へ任せる
#==================================
source s_internal    { internal(); };
destination d_stdout { file("/dev/stdout"); };
filter f_warnings    { level(warning..emerg); };

log {
  source(s_internal);
  filter(f_warnings);
  destination(d_stdout);
  flags(final);
};
